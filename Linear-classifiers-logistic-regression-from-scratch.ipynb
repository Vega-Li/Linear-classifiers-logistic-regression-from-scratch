{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The advanced model Group 11",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3nwMION6NbJ"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1_OwPP6F2Q1"
      },
      "source": [
        "class LogisticRegressionClassifier():\n",
        "  def __init__(self,alpha,lmbda,epsilon,maxiter):\n",
        "    self.alpha = float(alpha) # Learning rate\n",
        "    self.lmbda = float(lmbda) # Regularization constant\n",
        "    self.epsilon = float(epsilon) # Convergence measure\n",
        "    self.maxiter = int(maxiter) # The maximum number of iterations\n",
        "    self.threshold = 0.5 # The class prediction threshold\n",
        "    self.log = np.zeros(self.maxiter)\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"<logistic Regression Classifier Instance: alpha=\" + str(self.alpha) + \">\\n\"\n",
        "\n",
        "  def get_proba(self,X):\n",
        "    return np.array(1.0/(1 + np.exp(- np.dot(X,(self.theta).T))))\n",
        "    \n",
        "  def predict_proba(self,X):\n",
        "    X_ = self.add_ones(X)\n",
        "    return self.get_proba(X_)\n",
        "\n",
        "  def predict(self,X):\n",
        "    if X.ndim == 1:\n",
        "      y_pred = [self.predict_proba(X) > self.threshold]\n",
        "    else:\n",
        "      y_pred = [proba > self.threshold for proba in self.predict_proba(X)]\n",
        "\n",
        "    return np.array(y_pred)\n",
        "\n",
        "  def add_ones(self,X):\n",
        "    if X.ndim == 1:\n",
        "      return np.insert(X, 0, 1)\n",
        "    else:\n",
        "      return np.insert(X, 0, 1, 1)\n",
        "      \n",
        "  def fit(self, X_, y):\n",
        "    # Optimizing the parameters for the logistic regression classification model\n",
        "    X = self.add_ones(X_) # Bias terms\n",
        "\n",
        "    # Initialize optimization matrix\n",
        "    self.n = X.shape[0] # Instances\n",
        "    self.m = X.shape[1] # Features\n",
        "    self.probability = np.zeros(self.n) # Output probabilities\n",
        "    self.theta = np.random.rand(self.m)  # Weight Matrix\n",
        "    #self.theta = np.ones(self.m)\n",
        "\n",
        "    # Iterate through the data at most maxiter times, also stop iterating if error is less than epsilon\n",
        "    #print('iter | magnitude of the gradient')\n",
        "    for iteration in range(self.maxiter):\n",
        "      alpha = self.alpha/(iteration/200+1)\n",
        "      # Calculate probabilities\n",
        "      self.probability = self.get_proba(X)\n",
        "\n",
        "      # Calculate the gradient and update theta\n",
        "      #gw = (1.0/self.n) * (X.T @ (self.probability - y))\n",
        "      gw = X.T @ (self.probability - y)\n",
        "      g0 = gw[0] # save the theta_0 gradient calculation before regularization\n",
        "      #gw += ((self.lmbda * self.theta)/self.n) # regularize using the lmbda term\n",
        "      gw += (self.lmbda * self.theta) # regularize using the lmbda term\n",
        "      gw[0] = g0 # restore regularization independent theta_0 gradient calculation\n",
        "      self.theta -= alpha * gw # update paramters\n",
        "\n",
        "      # check for convergence\n",
        "      loss = np.linalg.norm(gw)\n",
        "      self.log[iteration] = loss\n",
        "      if self.epsilon > loss**2:\n",
        "        break\n",
        "\n",
        "      #print(iteration, ':', loss)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JDw7z2Xn6tx"
      },
      "source": [
        "def Accueval(Y_test, Y_proba):\n",
        "  accuary = 1 - np.mean(np.abs(Y_test - Y_proba))\n",
        "  return accuary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92dLpVlQnX6I"
      },
      "source": [
        "def data_preprocess(data_file, test_data, colomn_selected):\n",
        "\n",
        "  data = np.array(pd.read_csv(data_file))\n",
        "  X_origin = data[:,:-1]\n",
        "\n",
        "  X_pre = np.hstack([X_origin,X_origin**2])\n",
        "  X_selected = X_pre[:,colomn_selected]\n",
        "  X_mean = np.mean(X_selected,axis=0)\n",
        "  X_std = np.std(X_selected,axis=0)\n",
        "  X = (X_selected - X_mean)/X_std\n",
        "  Y = data[:,-1]\t\n",
        "\n",
        "  data_test = np.array(pd.read_csv(test_data))\n",
        "  X_test_origin = data_test[:,:-1]\n",
        "  X_test_pre = np.hstack([X_test_origin,X_test_origin**2])\n",
        "  X_test_selected = X_test_pre[:,colomn_selected]\n",
        "  X_test = (X_test_selected - X_mean)/X_std\n",
        "  Y_test = data_test[:,-1]\n",
        "\n",
        "  return X, Y, X_test, Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr06M7rK9u8v"
      },
      "source": [
        "def main(data_file, test_data, alpha=0.01, lmbda=0, epsilon=0.0001, maxiter=10000):\n",
        "\t\n",
        "  if data_file == 'hepatitis_train.csv':\n",
        "    column = [2,11,16,17,18]\n",
        "  elif data_file == 'bankrupcy_train.csv':\n",
        "    column = [23,33,34,47,49,55,62,68,76,83,86,93,107,115,127]\n",
        "  else:\n",
        "    print('Sorry, we have not optimize our model for this dataset.')\n",
        "    return\n",
        "\n",
        "  X, Y, X_test, Y_test = data_preprocess(data_file, test_data, column)\n",
        "\n",
        "\t# validation matrix\n",
        "  Accuary = np.zeros(X.shape[0],float)\n",
        " \n",
        "\t# K-fold cross validation\n",
        "  for k in range(0, X.shape[0], 10):\n",
        "\t\t# split the dataset into training subset and validation subset\n",
        "    X_vali = X[k:k+10,:]\n",
        "    Y_vali = Y[k:k+10]\n",
        "    X_train = np.vstack([X[0:k, :], X[k+10:, :]])\n",
        "    Y_train = np.hstack([Y[:k], Y[k+10:]])\n",
        "\n",
        "\t\t# create the logistic regression classifier using the training data\n",
        "    LRC = LogisticRegressionClassifier(alpha, lmbda, epsilon, maxiter)\n",
        "\n",
        "\t\t# fit the model to the loaded training data\n",
        "    LRC.fit(X_train, Y_train)\n",
        "\n",
        "\t\t# predict the results for the validation data\n",
        "    Y_vali_proba = LRC.predict_proba(X_vali)\n",
        "\n",
        "\t\t# kth validation result\n",
        "    Accuary[k] = Accueval(Y_vali, Y_vali_proba)\n",
        "\t\n",
        "\t\n",
        "\t# validation results for this model\n",
        "  Accuary = Accuary[::10]\n",
        "  Acc_train = np.mean(Accuary)\n",
        "  print('Average accuracy in cross validation: ' + str(Acc_train))\n",
        "\n",
        "\t# get final model\n",
        "  LRC = LogisticRegressionClassifier(alpha, lmbda, epsilon, maxiter)\n",
        "  print(\"\\nCreated a logistic regression classifier =\", LRC)\n",
        "\n",
        "  print(\"Fitting the training data...\\n\")\n",
        "  print(\"The weight matrix is:\\n\")\n",
        "  LRC.fit(X, Y)\n",
        "  print(LRC.theta)\n",
        "\n",
        "\t# predict the results for the test data\n",
        "  print(\"\\nGenerating probability prediction for the test data...\\n\")\n",
        "  Y_proba = LRC.predict_proba(X_test)\n",
        "  Y_pred = LRC.predict(X_test)\n",
        "  print(Y_pred)\n",
        "\n",
        "#  print(\"The probabilities for each instance in the test set are:\\n\")\n",
        "#  for prob in LRC.predict_proba(X_test):\n",
        "#    print(prob)\n",
        "\n",
        "\t# Accuary\n",
        "  accu = Accueval(Y_test, Y_proba)\n",
        "  print('\\nAccuracy in testing: ' + str(accu))\t\n",
        "  return LRC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAFLoujx8YrH",
        "outputId": "b0a53cac-44d2-4db5-fbf3-1584b59e0e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "main('hepatitis_train.csv', 'hepatitis_test.csv', alpha=0.1, lmbda=0, epsilon=0.01, maxiter=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy in cross validation: 0.7950685230811794\n",
            "\n",
            "Created a logistic regression classifier = <logistic Regression Classifier Instance: alpha=0.1>\n",
            "\n",
            "Fitting the training data...\n",
            "\n",
            "The weight matrix is:\n",
            "\n",
            "[ 2.1991571   0.25227407  0.5129146   0.62388065  0.45431409 -0.3887027 ]\n",
            "\n",
            "Generating probability prediction for the test data...\n",
            "\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            " False False  True  True  True  True  True  True]\n",
            "\n",
            "Accuracy in testing: 0.7495695188855812\n",
            "Running time: 0.10585199999999961 Seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}